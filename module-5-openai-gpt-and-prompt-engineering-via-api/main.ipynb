{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Projeto Desenvolvido na Data Science Academy - www.datascienceacademy.com.br -->\n",
    "# <font color='blue'>Data Science Academy</font>\n",
    "## <font color='blue'>IA Generativa e LLMs Para Processamento de Linguagem Natural</font>\n",
    "## <font color='blue'>Projeto 1</font>\n",
    "## <font color='blue'>Converse com Seus PDFs - Criando Assistente Pessoal de IA com LLM e VectorDB</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalando e Carregando Pacotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para instalar todos os pacotes de uma vez, execute no terminal ou prompt de comando:\n",
    "\n",
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import openai\n",
    "import langchain\n",
    "import chromadb\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.llms import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraindo Texto de Arquivos PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para ler os arquivos em pdf\n",
    "def dsa_read_pdf(directory_path):\n",
    "    \n",
    "    # Acessa a pasta com o arquivo pdf\n",
    "    file_loader = PyPDFDirectoryLoader(directory_path)\n",
    "    \n",
    "    # Lê o documento da pasta\n",
    "    documents = file_loader.load()\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executa a função\n",
    "dsa_doc = dsa_read_pdf('arquivos/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsa_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dsa_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo a API do LLM\n",
    "\n",
    "Crie sua API na OpenAI e coloque no arquivo .env na mesma pasta onde está este Jupyter Notebook.\n",
    "\n",
    "https://platform.openai.com/\n",
    "\n",
    "https://platform.openai.com/api-keys\n",
    "\n",
    "https://platform.openai.com/docs/quickstart?context=python\n",
    "<!-- Projeto Desenvolvido na Data Science Academy - www.datascienceacademy.com.br -->\n",
    "Veja mais detalhes no videobook do Capítulo 5 do curso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando as variáveis de ambiente definidas no arquivo .env\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando o Gerador de Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o gerador de embeddings\n",
    "gerador_embeddings = OpenAIEmbeddings(api_key = os.environ['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O OpenAIEmbeddings é uma funcionalidade que permite obter representações vetoriais (embeddings) de texto, que são úteis para várias tarefas de processamento de linguagem natural, como comparação de semelhança de texto, agrupamento e classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(gerador_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando os Vetores de Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testando o gerador de embeddings\n",
    "vetores = gerador_embeddings.embed_query('Qual habilidade mais importante na era da IA?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(vetores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vetores[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo o Vector Store\n",
    "\n",
    "https://www.trychroma.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo o nome do índice\n",
    "index_name = 'dsa-index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o vector store\n",
    "index = Chroma.from_documents(dsa_doc, gerador_embeddings, collection_name = index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja mais detalhes sobre o Chroma no videobook do Capítulo 5 do curso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a função de busca por similaridade\n",
    "def dsa_busca_similaridade(query, k = 2):\n",
    "    \n",
    "    # Utiliza o método 'similarity_search' do objeto 'index' para buscar os 'k' resultados \n",
    "    # mais semelhantes à 'query'\n",
    "    matching_results = index.similarity_search(query, k)\n",
    "    \n",
    "    # Retorna os resultados correspondentes da busca de similaridade\n",
    "    return matching_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Projeto Desenvolvido na Data Science Academy - www.datascienceacademy.com.br -->\n",
    "## Criando a App do Assistente Pessoal com LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria instância do LLM\n",
    "llm_dsa = OpenAI(openai_api_key = os.environ['OPENAI_API_KEY'], temperature = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/modules/chains/document/stuff\n",
    "\n",
    "https://js.langchain.com/docs/use_cases/question_answering/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria a chain para perguntas e respostas em documentos\n",
    "chain = load_qa_chain(llm_dsa, chain_type = 'stuff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a função para obter resposta\n",
    "def obter_resposta(query):\n",
    "\n",
    "    # Chama a função 'dsa_busca_similaridade' com a 'query' fornecida e armazena o resultado em 'doc_search'\n",
    "    doc_search = dsa_busca_similaridade(query)\n",
    "        \n",
    "    # Utiliza o objeto 'chain' para executar a função run e processar a 'query' e os documentos encontrados, \n",
    "    # armazenando a resposta em 'response'\n",
    "    response = chain.run(input_documents = doc_search, question = query)\n",
    "    \n",
    "    # Retorna a resposta obtida do processamento anterior\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executando o Assistente de IA e Conversando com PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pergunta para o arquivo pdf\n",
    "dsa_prompt1 = \"O que a pesquisa recente da Salesforce descobriu?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtém a resposta\n",
    "resposta1 = obter_resposta(dsa_prompt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resposta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pergunta para o arquivo pdf\n",
    "dsa_prompt2 = \"Qual percentual de empregadores estão tendo problemas para preencher vagas digitais com candidatos qualificados?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtém a resposta\n",
    "resposta2 = obter_resposta(dsa_prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resposta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pergunta para o arquivo pdf\n",
    "dsa_prompt3 = \"Qual a habilidade mais importante na era da Inteligência Artificial?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtém a resposta\n",
    "resposta3 = obter_resposta(dsa_prompt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resposta3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%watermark -a \"Data Science Academy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%watermark -v -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%watermark --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
